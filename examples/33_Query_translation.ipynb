{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POWZoSJR6XzK"
   },
   "source": [
    "# Query translation\n",
    "\n",
    "txtai supports two main types of queries: natural language statements and SQL statements. Natural language queries handles a search engine like query. SQL statements enable more complex filtering, sorting and column selection. Query translation bridges the gap between the two and enables filtering for natural language queries.\n",
    "\n",
    "For example, the query:\n",
    "\n",
    "```\n",
    "Tell me a feel good story since yesterday\n",
    "```\n",
    "\n",
    "becomes\n",
    "\n",
    "```sql\n",
    "select * from txtai where similar(\"Tell me a feel good story\") and\n",
    "entry >= date('now', '-1 day')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qa_PPKVX6XzN"
   },
   "source": [
    "# Install dependencies\n",
    "\n",
    "Install `txtai` and all dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "24q-1n5i6XzQ"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/neuml/txtai#egg=txtai[pipeline]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0p3WCDniUths"
   },
   "source": [
    "# Create index\n",
    "Let's first recap how to create an index. We'll use the classic txtai example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2j_CFGDR6Xzp",
    "outputId": "e65238c5-d67f-4fe4-9cbf-c88b0ff3a8bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ematos/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package cmudict to /home/ematos/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cmudict.zip.\n",
      "/home/ematos/miniconda3/envs/txtai-env/lib/python3.12/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'underscore_attrs_are_private' has been removed\n",
      "  warnings.warn(message, UserWarning)\n",
      "/home/ematos/miniconda3/envs/txtai-env/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '4',\n",
       "  'text': 'Maine man wins $1M from $25 lottery ticket',\n",
       "  'score': 0.08329008519649506}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from txtai.embeddings import Embeddings\n",
    "\n",
    "data = [\"US tops 5 million confirmed virus cases\",\n",
    "        \"Canada's last fully intact ice shelf has suddenly collapsed, forming a Manhattan-sized iceberg\",\n",
    "        \"Beijing mobilises invasion craft along coast as Taiwan tensions escalate\",\n",
    "        \"The National Park Service warns against sacrificing slower friends in a bear attack\",\n",
    "        \"Maine man wins $1M from $25 lottery ticket\",\n",
    "        \"Make huge profits without work, earn up to $100,000 a day\"]\n",
    "\n",
    "# Create embeddings index with content enabled. The default behavior is to only store indexed vectors.\n",
    "embeddings = Embeddings({\"path\": \"sentence-transformers/nli-mpnet-base-v2\", \"content\": True})\n",
    "\n",
    "# Create an index for the list of text\n",
    "embeddings.index([(uid, text, None) for uid, text in enumerate(data)])\n",
    "\n",
    "# Run a search\n",
    "embeddings.search(\"feel good story\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTee7YMNDD4R"
   },
   "source": [
    "# Query translation models\n",
    "\n",
    "Next we'll explore how query translation models work with examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04iOgP_ojSfK",
    "outputId": "41e73130-75e6-4ae9-b690-685972a13565"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7aad602f91d4dd0b96982d7e7502b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef45b8945bee41c3abb678d4ff739954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa20c7e8130a4530bcb1b1fa842d142e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97527d2e5fb435fa98d67f034aa4beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f806e1c7bf6466ab18d290271acb420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d55b4bf349240a2a11dd9985d4d5f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: feel good story\n",
      "SQL: select id, text, score from txtai where similar('feel good story')\n",
      "\n",
      "Input: feel good story since yesterday\n",
      "SQL: select id, text, score from txtai where similar('feel good story') and entry >= date('now', '-1 day')\n",
      "\n",
      "Input: feel good story with lottery in text\n",
      "SQL: select id, text, score from txtai where similar('feel good story') and text like '%lotterie%'\n",
      "\n",
      "Input: how many feel good story\n",
      "SQL: select count(*) from txtai where similar('feel good story')\n",
      "\n",
      "Input: feel good story translated to fr\n",
      "SQL: select id, translate(text, 'fr') text, score from txtai where similar('feel good story')\n",
      "\n",
      "Input: feel good story summarized\n",
      "SQL: select id, summary(text) text, score from txtai where similar('feel good story')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from txtai.pipeline import Sequences\n",
    "\n",
    "sequences = Sequences(\"NeuML/t5-small-txtsql\")\n",
    "\n",
    "queries = [\n",
    "  \"feel good story\",\n",
    "  \"feel good story since yesterday\",\n",
    "  \"feel good story with lottery in text\",\n",
    "  \"how many feel good story\",\n",
    "  \"feel good story translated to fr\",\n",
    "  \"feel good story summarized\"\n",
    "]\n",
    "\n",
    "# Prefix to pass to T5 model\n",
    "prefix = \"translate English to SQL: \"\n",
    "\n",
    "for query in queries:\n",
    "  print(f\"Input: {query}\")\n",
    "  print(f\"SQL: {sequences(query, prefix)}\")\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAnEMaiWlOXm"
   },
   "source": [
    "Looking at the query translations above gives an idea on how this model works.\n",
    "\n",
    "[t5-small-txtsql](https://huggingface.co/NeuML/t5-small-txtsql) is the default model. Custom domain query syntax languages can be created using this same methodology, including for other languages. Natural language can be translated to functions, query clauses, column selection and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9hOcgNfjSyL"
   },
   "source": [
    "# Natural language filtering\n",
    "\n",
    "Now it's time for this in action! Let's first initialize the embeddings index with the appropriate settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L2DDJrd0RAaN",
    "outputId": "c60bfc29-187b-4926-8656-04063b2ca85c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ematos/miniconda3/envs/txtai-env/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/home/ematos/miniconda3/envs/txtai-env/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'url_to_filename' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` to benefit from the new cache layout.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73393a2931bb41e6bdae01fcaf4a5d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a3f339a03f4c00b78a197b04dd8a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2544c5acfd24c6cb57d6f6cff122a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ed44f46aaa4161b5e58dba5b85473b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9aaafb823e4de582c41a4cee6d07b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01240e22b4e64b8184875d7239d79766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48bc153ca643445eb0d008e08b8c05ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '4',\n",
       " 'score': 0.08329008519649506,\n",
       " 'text': 'Maine Mann gewinnt $1M von $25 Lotterie-Ticket'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from txtai.pipeline import Translation\n",
    "\n",
    "def translate(text, lang):\n",
    "  return translation(text, lang)\n",
    "\n",
    "translation = Translation()\n",
    "\n",
    "# Create embeddings index with content enabled. The default behavior is to only store indexed vectors.\n",
    "embeddings = Embeddings({\"path\": \"sentence-transformers/nli-mpnet-base-v2\",\n",
    "                         \"content\": True,\n",
    "                         \"query\": {\"path\": \"NeuML/t5-small-txtsql\"},\n",
    "                         \"functions\": [translate]})\n",
    "\n",
    "# Create an index for the list of text\n",
    "embeddings.index([(uid, text, None) for uid, text in enumerate(data)])\n",
    "\n",
    "query = \"select id, score, translate(text, 'de') 'text' from txtai where similar('feel good story')\"\n",
    "\n",
    "# Run a search using a custom SQL function\n",
    "embeddings.search(query)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNd7QmFmnh-f"
   },
   "source": [
    "Note how the query model was provided as a embeddings index configuration parameter. Custom SQL functions were also added in. Let's now see if the same SQL statement can be run with a natural language query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnGSBNMonur2",
    "outputId": "dc14d898-b46f-42e6-88e0-434863cc15d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '4',\n",
       " 'text': 'Maine Mann gewinnt $1M von $25 Lotterie-Ticket',\n",
       " 'score': 0.08329008519649506}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.search(\"feel good story translated to de\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnmVUK2DoZkh"
   },
   "source": [
    "Same result. Let's try a few more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Js2b_M61oitg",
    "outputId": "fab080cb-d082-4cf3-8314-12d23acc3c02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '4',\n",
       " 'text': 'Maine man wins $1M from $25 lottery ticket',\n",
       " 'score': 0.08329008519649506}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.search(\"feel good story since yesterday\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcxPgriwomWv",
    "outputId": "7e71dd09-7c4f-4147-ba9e-47a45c1cf90f"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeel good story with lottery in text\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "embeddings.search(\"feel good story with lottery in text\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ob4Q_CLpGBm"
   },
   "source": [
    "For good measure, a couple queries with filters that return no results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMaf7JJzonAC",
    "outputId": "71080bd1-2d9e-41ba-9501-2cdedaf26d6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.search(\"feel good story with missing in text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADFNLhvto_0J",
    "outputId": "12e08ea8-7203-4fb0-cb84-1133b5db9dc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.search(\"feel good story with field equal 14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTT8nopiRdVH"
   },
   "source": [
    "# Query translation with applications\n",
    "\n",
    "Of course this is all available with YAML-configured applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZ_7G6M4RUbz",
    "outputId": "b00ce1c2-8df2-4289-8d03-991174a0e74f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '4',\n",
       " 'text': 'Maine Mann gewinnt $1M von $25 Lotterie-Ticket',\n",
       " 'score': 0.08329008519649506}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "translation:\n",
    "\n",
    "writable: true\n",
    "embeddings:\n",
    "  path: sentence-transformers/nli-mpnet-base-v2\n",
    "  content: true\n",
    "  query:\n",
    "    path: NeuML/t5-small-txtsql\n",
    "  functions:\n",
    "    - {name: translate, argcount: 2, function: translation}\n",
    "\"\"\"\n",
    "\n",
    "from txtai.app import Application\n",
    "\n",
    "# Build application and index data\n",
    "app = Application(config)\n",
    "app.add([{\"id\": x, \"text\": row} for x, row in enumerate(data)])\n",
    "app.index()\n",
    "\n",
    "# Run search query\n",
    "app.search(\"feel good story translated to de\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDIF3tYt6X0O"
   },
   "source": [
    "# Wrapping up\n",
    "\n",
    "This notebook introduced natural language filtering with query translation models. This powerful feature adds filtering and pipelines to natural language statements. Custom domain-specific query languages can be created to enable rich queries natively in txtai."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
