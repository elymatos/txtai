{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc1f839-c5b0-436b-85eb-ce0d3089ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming tokens to temporary file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  2748\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   45391 lr:  0.000000 avg.loss:  2.730300 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14160\n",
      "-rw-r--r-- 1 ematos ematos 4685824 set  7 17:39 pk-dataset.magnitude\n",
      "-rw-r--r-- 1 ematos ematos 9808984 set  7 17:39 pk-dataset.txt\n",
      "-rw-r--r-- 1 ematos ematos    2223 set  7 17:38 test_sqlite.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import tempfile\n",
    "\n",
    "from txtai.pipeline import Tokenizer\n",
    "from txtai.vectors import WordVectors\n",
    "\n",
    "print(\"Streaming tokens to temporary file\")\n",
    "\n",
    "# Stream tokens to temp working file\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".txt\", delete=False) as output:\n",
    "  # Save file path\n",
    "  tokens = output.name\n",
    "\n",
    "  db_dir = os.path.abspath(\"/home/ematos/devel/kardec/kardec_laravel/database\")\n",
    "  database_file = os.path.join(db_dir, \"dataset.txtai.sqlite3\")\n",
    "\n",
    "  db = sqlite3.connect(database_file)\n",
    "  cur = db.cursor()\n",
    "  cur.execute(\"SELECT sentence from sentence\")\n",
    "\n",
    "  for row in cur:\n",
    "    output.write(\" \".join(Tokenizer.tokenize(row[0])) + \"\\n\")\n",
    "\n",
    "  # Free database resources\n",
    "  db.close()\n",
    "\n",
    "# Build word vectors model - 300 dimensions, 3 min occurrences\n",
    "WordVectors.build(tokens, 300, 3, \"pk-dataset\")\n",
    "\n",
    "# Remove temporary tokens file\n",
    "os.remove(tokens)\n",
    "\n",
    "# Show files\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4db3a92-382f-4a38-8251-d67a63f5610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterated over 4900 total rows\n",
      "Iterated over 4900 total rows\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "import regex as re\n",
    "\n",
    "from txtai.embeddings import Embeddings\n",
    "from txtai.pipeline import Tokenizer\n",
    "\n",
    "def stream():\n",
    "  # Connection to database file\n",
    "  db_dir = os.path.abspath(\"/home/ematos/devel/kardec/kardec_laravel/database\")\n",
    "  database_file = os.path.join(db_dir, \"dataset.txtai.sqlite3\")\n",
    "\n",
    "  db = sqlite3.connect(database_file)\n",
    "  cur = db.cursor()\n",
    "\n",
    "  # Select tagged sentences without a NLP label. NLP labels are set for non-informative sentences.\n",
    "  cur.execute(\"SELECT idSentence,idItem,sentence from sentence\")\n",
    "\n",
    "  count = 0\n",
    "  for row in cur:\n",
    "    # Unpack row\n",
    "    uid, name, text = row\n",
    "\n",
    "    # Only process certain document sections\n",
    "    # if not name or not re.search(r\"background|(?<!.*?results.*?)discussion|introduction|reference\", name.lower()):\n",
    "      # Tokenize text\n",
    "    tokens = Tokenizer.tokenize(text)\n",
    "\n",
    "    document = (uid, tokens, None)\n",
    "\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "      print(\"Streamed %d documents\" % (count), end=\"\\r\")\n",
    "\n",
    "    # Skip documents with no tokens parsed\n",
    "    if tokens:\n",
    "      yield document\n",
    "\n",
    "  print(\"Iterated over %d total rows\" % (count))\n",
    "\n",
    "  # Free database resources\n",
    "  db.close()\n",
    "\n",
    "# BM25 + fastText vectors\n",
    "embeddings = Embeddings({\"path\": \"pk-dataset.magnitude\",\n",
    "                         \"scoring\": \"bm25\",\n",
    "                         \"pca\": 3})\n",
    "\n",
    "# Build scoring index if scoring method provided\n",
    "if embeddings.config.get(\"scoring\"):\n",
    "  embeddings.score(stream())\n",
    "\n",
    "# Build embeddings index\n",
    "embeddings.index(stream())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e7aaf16-7bd6-4348-8ad0-3ca2af179b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4628\n",
      "3602\n",
      "644\n",
      "657\n",
      "3599\n",
      "3601\n",
      "3833\n",
      "3600\n",
      "379\n",
      "2505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idSentence</th>\n",
       "      <th>idItem</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4628</td>\n",
       "      <td>284</td>\n",
       "      <td>AK.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3602</td>\n",
       "      <td>241</td>\n",
       "      <td>Haverá outra às 16h10, que chegará às 22h15.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>644</td>\n",
       "      <td>81</td>\n",
       "      <td>Ao Sr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>657</td>\n",
       "      <td>82</td>\n",
       "      <td>Paris, 17 de Fevereiro de 1863  Sf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3599</td>\n",
       "      <td>241</td>\n",
       "      <td>Há uma às 7h50 que chega a Paris às 15h45, e outra às 18h que chega a Paris às 5h15.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3601</td>\n",
       "      <td>241</td>\n",
       "      <td>Pelo trem de correios, a partir de 15 de maio, a partida será às 6h55 e chegará a Paris às 12h20.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3833</td>\n",
       "      <td>250</td>\n",
       "      <td>Sic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>241</td>\n",
       "      <td>A partir de 15 de maio, o horário será modificado da seguinte forma: primeira partida de Tours às 8h30, chegada a Paris às 16h20; segunda partida às 20h15, chegada a Paris às 4h20.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>59</td>\n",
       "      <td>Senhor Houat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2505</td>\n",
       "      <td>187</td>\n",
       "      <td>Parto decididamente na quarta-feira no comboio das 10h25 da manhã, que chega em Paris à noite, às 18h20.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "db_dir = os.path.abspath(\"/home/ematos/devel/kardec/kardec_laravel/database\")\n",
    "database_file = os.path.join(db_dir, \"dataset.txtai.sqlite3\")\n",
    "\n",
    "db = sqlite3.connect(database_file)\n",
    "\n",
    "cur = db.cursor()\n",
    "\n",
    "results = []\n",
    "for uid, score in embeddings.search(\"intelectuais que não sabem conversar\", 10):\n",
    "\n",
    "  print(uid)\n",
    "    \n",
    "  cur.execute(\"SELECT idSentence, sentence FROM sentence WHERE idSentence = ?\", [uid])\n",
    "  uid, text = cur.fetchone()\n",
    "\n",
    "  cur.execute(\"SELECT idSentence, idItem from sentence where idSentence = ?\", [uid])\n",
    "  results.append(cur.fetchone() + (text,))\n",
    "\n",
    "# Free database resources\n",
    "db.close()\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"idSentence\",\"idItem\", \"sentence\"])\n",
    "\n",
    "# It has been reported that displaying HTML within VSCode doesn't work.\n",
    "# When using VSCode, the data can be exported to an external HTML file to view.\n",
    "# See example below.\n",
    "\n",
    "# htmlData = df.to_html(index=False)\n",
    "# with open(\"data.html\", \"w\") as file:\n",
    "#     file.write(htmlData)\n",
    "\n",
    "display(HTML(df.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18da54-c3ef-44b9-bbf0-96edb10cc469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
