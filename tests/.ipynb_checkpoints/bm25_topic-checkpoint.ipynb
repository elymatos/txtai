{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3f9ac4-8993-472b-93b8-dbed0156db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/neuml/txtai#egg=txtai[graph] datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c70996a3-2b7e-4801-8c30-13fc91f76eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4299"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mysql.connector as mariadb\n",
    "import sys\n",
    "\n",
    "from txtai.scoring import ScoringFactory\n",
    "\n",
    "# Connect to MariaDB Platform\n",
    "try:\n",
    "    conn = mariadb.connect(\n",
    "        user=\"kardec\",\n",
    "        password=\"ak2019\",\n",
    "        host=\"localhost\",\n",
    "        port=3306,\n",
    "        database=\"kardec_db\"\n",
    "\n",
    "    )\n",
    "except mariadb.Error as e:\n",
    "    print(f\"Error connecting to MariaDB Platform: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Get Cursor\n",
    "cur = conn.cursor()\n",
    "# Select tagged sentences without a NLP label. NLP labels are set for non-informative sentences.\n",
    "cur.execute(\"SELECT idSentence as id, text, '' from ak_sentence where idlanguage=1\")\n",
    "\n",
    "# Build index\n",
    "scoring = ScoringFactory.create({\"method\": \"bm25\", \"terms\": True})\n",
    "scoring.index(cur)\n",
    "cur.fetchall()\n",
    "\n",
    "# Free database resources\n",
    "#conn.close()\n",
    "\n",
    "# Show total\n",
    "scoring.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42a9f9ab-9a67-496c-8174-b5393383efc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2887 Eis onde me encontro; vês que não avancei muito; no entanto, tenho alguma esperança. 6.6996846199035645\n",
      "3138 É desnecessário te dizer que todas as pessoas conhecidas que encontro te fazem mil elogios. 6.564478397369385\n",
      "5336 Eles marcaram um encontro com o senhor d’Ambel para organizar a sessão, a fim de que ela seja mais interessante. 5.962804317474365\n",
      "7281 Terminado o prazo, fui ao lugar indicado pelo indivíduo que eu chamava de misterioso; chegamos ao mesmo tempo ao encontro. 5.962804317474365\n",
      "3068 Abraça por mim teus bons pais e diz-lhes o quanto eu ficaria feliz se puder escapar por um momento para ir ao encontro deles. 5.462163925170898\n",
      "2103 Encontro uma grande prova disso naquelas poucas palavras aparentemente insignificantes, às quais não se dá importância, mas que foram o incidente mais característico da noite para o mundo invisível. 5.118370532989502\n"
     ]
    }
   ],
   "source": [
    "for id, score in scoring.search(\"encontro\", 6):\n",
    "  cur.execute(\"SELECT idSentence as id, text from ak_sentence where idSentence=%s and idlanguage=1\",(id,))  \n",
    "  result = cur.fetchone()\n",
    "#  myresult = cur.fetchall()\n",
    "#  for x in myresult:\n",
    "  print(result[0], result[1], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43a98aa0-a488-45c3-812f-3cbdf4b6721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "Error binding parameter 1: type 'tuple' is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#    graph.insert(cur)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m graph\u001b[38;5;241m.\u001b[39minsert((x, text, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m x, text \u001b[38;5;129;01min\u001b[39;00m texts)\n\u001b[0;32m---> 38\u001b[0m graph\u001b[38;5;241m.\u001b[39mindex(batchsearch, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/txtai-env/lib/python3.12/site-packages/txtai/graph/base.py:442\u001b[0m, in \u001b[0;36mGraph.index\u001b[0;34m(self, search, ids, similarity)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolverelations(ids)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# Infer node edges using search function\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minferedges(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan(), search)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Label categories/topics\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopics\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig:\n",
      "File \u001b[0;32m~/miniconda3/envs/txtai-env/lib/python3.12/site-packages/txtai/graph/base.py:624\u001b[0m, in \u001b[0;36mGraph.inferedges\u001b[0;34m(self, nodes, search, attributes)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;66;03m# Process batch\u001b[39;00m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m batchsize:\n\u001b[0;32m--> 624\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddbatch(search, batch, limit, minscore)\n\u001b[1;32m    625\u001b[0m         batch \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch:\n",
      "File \u001b[0;32m~/miniconda3/envs/txtai-env/lib/python3.12/site-packages/txtai/graph/base.py:643\u001b[0m, in \u001b[0;36mGraph.addbatch\u001b[0;34m(self, search, batch, limit, minscore)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03mAdds batch of documents to graph. This method runs the search function for each item in batch\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03mand adds node edges between the input and each search result.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    minscore: min score to add node edge\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    642\u001b[0m edges \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(search([data \u001b[38;5;28;01mfor\u001b[39;00m _, data \u001b[38;5;129;01min\u001b[39;00m batch], limit)):\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;66;03m# Get input node id\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m batch[x]\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;66;03m# Add edges for each input node id and result node id pair that meets specified criteria\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[45], line 27\u001b[0m, in \u001b[0;36mbatchsearch\u001b[0;34m(queries, limit)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(limit)\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m [(query, limit) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries]\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SCORING\u001b[38;5;241m.\u001b[39msearch(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/txtai-env/lib/python3.12/site-packages/txtai/scoring/tfidf.py:163\u001b[0m, in \u001b[0;36mTFIDF.search\u001b[0;34m(self, query, limit)\u001b[0m\n\u001b[1;32m    160\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize(query) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m query\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Get topn term query matches\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterms\u001b[38;5;241m.\u001b[39msearch(query, limit)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Normalize scores, if enabled\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize \u001b[38;5;129;01mand\u001b[39;00m scores:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Calculate max score = best score for this query + average index score\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Limit max to 6 * average index score\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/txtai-env/lib/python3.12/site-packages/txtai/scoring/terms.py:180\u001b[0m, in \u001b[0;36mTerms.search\u001b[0;34m(self, terms, limit)\u001b[0m\n\u001b[1;32m    177\u001b[0m terms, skipped, hasscores \u001b[38;5;241m=\u001b[39m Counter(terms), {}, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m term, freq \u001b[38;5;129;01min\u001b[39;00m terms\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Compute or lookup term weights\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     uids, weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights(term)\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m uids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;66;03m# Term considered common if it appears in more than 10% of index\u001b[39;00m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uids) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcutoff \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mids):\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;66;03m# Add scores\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/txtai-env/lib/python3.12/site-packages/txtai/scoring/terms.py:411\u001b[0m, in \u001b[0;36mTerms.weights\u001b[0;34m(self, term)\u001b[0m\n\u001b[1;32m    408\u001b[0m lengths \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlengths, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock:\n\u001b[0;32m--> 411\u001b[0m     uids, freqs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup(term)\n\u001b[1;32m    412\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m uids:\n",
      "File \u001b[0;32m~/miniconda3/envs/txtai-env/lib/python3.12/site-packages/txtai/scoring/terms.py:382\u001b[0m, in \u001b[0;36mTerms.lookup\u001b[0;34m(self, term)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03mRetrieves a term frequency sparse array.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m    term frequency sparse array\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    380\u001b[0m uids, freqs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor\u001b[38;5;241m.\u001b[39mexecute(Terms\u001b[38;5;241m.\u001b[39mSELECT_TERMS, [term])\u001b[38;5;241m.\u001b[39mfetchone()\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    384\u001b[0m     uids, freqs \u001b[38;5;241m=\u001b[39m (array(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m), array(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mProgrammingError\u001b[0m: Error binding parameter 1: type 'tuple' is not supported"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from txtai.graph import GraphFactory\n",
    "\n",
    "# Multiprocessing helper methods\n",
    "#SCORING = None\n",
    "\n",
    "#def create(search):\n",
    "#    global SCORING\n",
    "\n",
    "    # Create a global scoring object\n",
    "#    SCORING = search\n",
    "\n",
    "SCORING = scoring\n",
    "\n",
    "def run(params):\n",
    "    print(params)\n",
    "    query, limit = params\n",
    "    return SCORING.search(query, limit)\n",
    "\n",
    "def batchsearch(queries, limit):\n",
    "    #return run((query, limit) for query in queries)\n",
    "    return SCORING.search(queries,limit)\n",
    "\n",
    "cur.execute(\"SELECT idSentence as id, text from ak_sentence where idlanguage=1\")\n",
    "texts = cur.fetchall()\n",
    "\n",
    "# Build the graph\n",
    "#pool = None\n",
    "#with Pool(os.cpu_count(), initializer=create, initargs=(scoring,)) as pool:\n",
    "graph = GraphFactory.create({\"topics\": {}})\n",
    "#    graph.insert(cur)\n",
    "graph.insert((x, text, None) for x, text in texts)\n",
    "graph.index(batchsearch, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074f18f-5948-45ed-82f2-b08232a8b8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
